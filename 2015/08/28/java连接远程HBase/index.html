<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>java连接远程HBase 1.1.1 | 我的后院自留地</title>
  <meta name="author" content="okuc">
  
  <meta name="description" content="hadoop hive hbase cassandra linux elasticsearch eclipse java mysql spark titan tinkpop neo4j">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="java连接远程HBase 1.1.1"/>
  <meta property="og:site_name" content="我的后院自留地"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="我的后院自留地" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


<script type="text/javascript">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?7ea69d6de48b6d7cd2a53bcc519beadc";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">我的后院自留地</a></h1>
  <h2><a href="/">琴棋书画诗酒花 当年件件不离它 而今事事都变更 柴米油盐酱醋茶</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="//">首页</a></li>
    
      <li><a href="/archives">归档</a></li>
    
      <li><a href="/coding">编程技术</a></li>
    
      <li><a href="/bigData">大数据技术</a></li>
    
      <li><a href="/dataV">数据可视化</a></li>
    
      <li><a href="/about">关于</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-08-27T17:23:41.000Z"><a href="/2015/08/28/java连接远程HBase/">2015-08-28</a></time>
      
      
  
    <h1 class="title">java连接远程HBase 1.1.1</h1>
  

    </header>
    <div class="entry">
      
        <p>由于工作需要用到<code>HBase</code>，今晚使用<code>HBase 1.1.1</code>小试牛刀了一把。<code>HBase 1.1.1</code>运行环境为<code>CentOS7.0</code>，java客户端运行环境为<code>Win10</code>，服务端jdk版本为<code>1.8</code>，客户端jdk版本为<code>1.7</code>。</p>
<p><strong>提示：本文最后可下载源代码</strong></p>
<p>具体步骤如下：</p>
<ol>
<li>下载<code>HBase 1.1.1</code>,下载地址如下：<a href="http://mirrors.cnnic.cn/apache/hbase/1.1.1/hbase-1.1.1-bin.tar.gz" target="_blank" rel="external">http://mirrors.cnnic.cn/apache/hbase/1.1.1/hbase-1.1.1-bin.tar.gz</a>。</li>
<li>使用<code>tar -xvf hbase-1.1.1-bin.tar.gz</code>解压。<strong>我使用的是root用户</strong></li>
<li>进入到解压后的bin目录中，使用<code>./start-hbase.sh</code>启动Hbase，启动成功会显示如下提示：<pre><code>starting master, logging to /home/soft/hbase-1.1.1/bin/../logs/hbase-root-master-MiWiFi-R1CM.out
</code></pre><strong>由于没有作任何设置，此时，所有数据都保存在临时环境中，一旦重启就会丢失。</strong><a id="more"></a></li>
<li>在浏览器输入<code>http://192.168.90.161:16010</code>看看有信息输出没。<strong>网上普遍说端口是<code>60010</code>，但是我下载的版本端口号是<code>16010</code>，原因未知</strong></li>
<li><p>新建maven工程<code>HBaseHello</code>,设置groupid为<code>xyz.okuc</code>,原因是本站的一个隐藏域名是<a href="www.okuc.xyz">www.okuc.xyz</a>哟！<br> 首先在pom.xml文件中添加所依赖的jar包：</p>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
  &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;
  &lt;version&gt;1.1.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre></li>
<li><p>新建名为’HbaseTest’的java类，再贴上我从网上问度娘要来的代码：</p>
<pre><code>package xyz.okuc.HBaseHello;

import java.io.IOException; 
import java.util.ArrayList; 
import java.util.List; 

import org.apache.hadoop.conf.Configuration; 
import org.apache.hadoop.hbase.HBaseConfiguration; 
import org.apache.hadoop.hbase.HColumnDescriptor; 
import org.apache.hadoop.hbase.HTableDescriptor; 
import org.apache.hadoop.hbase.KeyValue; 
import org.apache.hadoop.hbase.MasterNotRunningException; 
import org.apache.hadoop.hbase.ZooKeeperConnectionException; 
import org.apache.hadoop.hbase.client.Delete; 
import org.apache.hadoop.hbase.client.Get; 
import org.apache.hadoop.hbase.client.HBaseAdmin; 
import org.apache.hadoop.hbase.client.HTable; 
import org.apache.hadoop.hbase.client.HTablePool; 
import org.apache.hadoop.hbase.client.Put; 
import org.apache.hadoop.hbase.client.Result; 
import org.apache.hadoop.hbase.client.ResultScanner; 
import org.apache.hadoop.hbase.client.Scan; 
import org.apache.hadoop.hbase.filter.Filter; 
import org.apache.hadoop.hbase.filter.FilterList; 
import org.apache.hadoop.hbase.filter.SingleColumnValueFilter; 
import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp; 
import org.apache.hadoop.hbase.util.Bytes; 

public class HbaseTest { 

    public static Configuration configuration; 
    static { 
        configuration = HBaseConfiguration.create(); 
        configuration.set(&quot;hbase.zookeeper.property.clientPort&quot;, &quot;2181&quot;); 
        configuration.set(&quot;hbase.zookeeper.quorum&quot;, &quot;192.168.90.161&quot;); 
        configuration.set(&quot;hbase.master&quot;, &quot;192.168.90.161:16000&quot;); 
    } 

    public static void main(String[] args) { 
         createTable(&quot;okuc&quot;); 
        // insertData(&quot;okuc&quot;); 
        // QueryAll(&quot;okuc&quot;); 
        // QueryByCondition1(&quot;okuc&quot;); 
        // QueryByCondition2(&quot;okuc&quot;); 
        //QueryByCondition3(&quot;okuc&quot;); 
        //deleteRow(&quot;okuc&quot;,&quot;abcdef&quot;); 
         //deleteByCondition(&quot;okuc&quot;,&quot;abcdef&quot;); 
    } 

    public static void createTable(String tableName) { 
        System.out.println(&quot;start create table ......&quot;); 
        try { 
            HBaseAdmin hBaseAdmin = new HBaseAdmin(configuration); 
            if (hBaseAdmin.tableExists(tableName)) {// 如果存在要创建的表，那么先删除，再创建 
                hBaseAdmin.disableTable(tableName); 
                hBaseAdmin.deleteTable(tableName); 
                System.out.println(tableName + &quot; is exist,detele....&quot;); 
            } 
            HTableDescriptor tableDescriptor = new HTableDescriptor(tableName); 
            tableDescriptor.addFamily(new HColumnDescriptor(&quot;column1&quot;)); 
            tableDescriptor.addFamily(new HColumnDescriptor(&quot;column2&quot;)); 
            tableDescriptor.addFamily(new HColumnDescriptor(&quot;column3&quot;)); 
            hBaseAdmin.createTable(tableDescriptor); 
        } catch (MasterNotRunningException e) { 
            e.printStackTrace(); 
        } catch (ZooKeeperConnectionException e) { 
            e.printStackTrace(); 
        } catch (IOException e) { 
            e.printStackTrace(); 
        } 
        System.out.println(&quot;end create table ......&quot;); 
    } 

    public static void insertData(String tableName) { 
        System.out.println(&quot;start insert data ......&quot;); 
        HTablePool pool = new HTablePool(configuration, 1000); 
        HTable table = (HTable) pool.getTable(tableName); 
        Put put = new Put(&quot;112233bbbcccc&quot;.getBytes());// 一个PUT代表一行数据，再NEW一个PUT表示第二行数据,每行一个唯一的ROWKEY，此处rowkey为put构造方法中传入的值 
        put.add(&quot;column1&quot;.getBytes(), null, &quot;aaa&quot;.getBytes());// 本行数据的第一列 
        put.add(&quot;column2&quot;.getBytes(), null, &quot;bbb&quot;.getBytes());// 本行数据的第三列 
        put.add(&quot;column3&quot;.getBytes(), null, &quot;ccc&quot;.getBytes());// 本行数据的第三列 
        try { 
            table.put(put); 
        } catch (IOException e) { 
            e.printStackTrace(); 
        } 
        System.out.println(&quot;end insert data ......&quot;); 
    } 

    public static void dropTable(String tableName) { 
        try { 
            HBaseAdmin admin = new HBaseAdmin(configuration); 
            admin.disableTable(tableName); 
            admin.deleteTable(tableName); 
        } catch (MasterNotRunningException e) { 
            e.printStackTrace(); 
        } catch (ZooKeeperConnectionException e) { 
            e.printStackTrace(); 
        } catch (IOException e) { 
            e.printStackTrace(); 
        } 

    } 

     public static void deleteRow(String tablename, String rowkey)  { 
        try { 
            HTable table = new HTable(configuration, tablename); 
            List list = new ArrayList(); 
            Delete d1 = new Delete(rowkey.getBytes()); 
            list.add(d1); 

            table.delete(list); 
            System.out.println(&quot;删除行成功!&quot;); 

        } catch (IOException e) { 
            e.printStackTrace(); 
        } 

    } 

     public static void deleteByCondition(String tablename, String rowkey)  { 
            //目前还没有发现有效的API能够实现根据非rowkey的条件删除这个功能能，还有清空表全部数据的API操作 

    } 

    public static void QueryAll(String tableName) { 
        HTablePool pool = new HTablePool(configuration, 1000); 
        HTable table = (HTable) pool.getTable(tableName); 
        try { 
            ResultScanner rs = table.getScanner(new Scan()); 
            for (Result r : rs) { 
                System.out.println(&quot;获得到rowkey:&quot; + new String(r.getRow())); 
                for (KeyValue keyValue : r.raw()) { 
                    System.out.println(&quot;列：&quot; + new String(keyValue.getFamily()) 
                            + &quot;====值:&quot; + new String(keyValue.getValue())); 
                } 
            } 
        } catch (IOException e) { 
            e.printStackTrace(); 
        } 
    } 

    public static void QueryByCondition1(String tableName) { 

        HTablePool pool = new HTablePool(configuration, 1000); 
        HTable table = (HTable) pool.getTable(tableName); 
        try { 
            Get scan = new Get(&quot;abcdef&quot;.getBytes());// 根据rowkey查询 
            Result r = table.get(scan); 
            System.out.println(&quot;获得到rowkey:&quot; + new String(r.getRow())); 
            for (KeyValue keyValue : r.raw()) { 
                System.out.println(&quot;列：&quot; + new String(keyValue.getFamily()) 
                        + &quot;====值:&quot; + new String(keyValue.getValue())); 
            } 
        } catch (IOException e) { 
            e.printStackTrace(); 
        } 
    } 

    public static void QueryByCondition2(String tableName) { 

        try { 
            HTablePool pool = new HTablePool(configuration, 1000); 
            HTable table = (HTable) pool.getTable(tableName); 
            Filter filter = new SingleColumnValueFilter(Bytes 
                    .toBytes(&quot;column1&quot;), null, CompareOp.EQUAL, Bytes 
                    .toBytes(&quot;aaa&quot;)); // 当列column1的值为aaa时进行查询 
            Scan s = new Scan(); 
            s.setFilter(filter); 
            ResultScanner rs = table.getScanner(s); 
            for (Result r : rs) { 
                System.out.println(&quot;获得到rowkey:&quot; + new String(r.getRow())); 
                for (KeyValue keyValue : r.raw()) { 
                    System.out.println(&quot;列：&quot; + new String(keyValue.getFamily()) 
                            + &quot;====值:&quot; + new String(keyValue.getValue())); 
                } 
            } 
        } catch (Exception e) { 
            e.printStackTrace(); 
        } 

    } 

    public static void QueryByCondition3(String tableName) { 

        try { 
            HTablePool pool = new HTablePool(configuration, 1000); 
            HTable table = (HTable) pool.getTable(tableName); 

            List&lt;Filter&gt; filters = new ArrayList&lt;Filter&gt;(); 

            Filter filter1 = new SingleColumnValueFilter(Bytes 
                    .toBytes(&quot;column1&quot;), null, CompareOp.EQUAL, Bytes 
                    .toBytes(&quot;aaa&quot;)); 
            filters.add(filter1); 

            Filter filter2 = new SingleColumnValueFilter(Bytes 
                    .toBytes(&quot;column2&quot;), null, CompareOp.EQUAL, Bytes 
                    .toBytes(&quot;bbb&quot;)); 
            filters.add(filter2); 

            Filter filter3 = new SingleColumnValueFilter(Bytes 
                    .toBytes(&quot;column3&quot;), null, CompareOp.EQUAL, Bytes 
                    .toBytes(&quot;ccc&quot;)); 
            filters.add(filter3); 

            FilterList filterList1 = new FilterList(filters); 

            Scan scan = new Scan(); 
            scan.setFilter(filterList1); 
            ResultScanner rs = table.getScanner(scan); 
            for (Result r : rs) { 
                System.out.println(&quot;获得到rowkey:&quot; + new String(r.getRow())); 
                for (KeyValue keyValue : r.raw()) { 
                    System.out.println(&quot;列：&quot; + new String(keyValue.getFamily()) 
                            + &quot;====值:&quot; + new String(keyValue.getValue())); 
                } 
            } 
            rs.close(); 

        } catch (Exception e) { 
            e.printStackTrace(); 
        } 

    } 

}
</code></pre><p><strong>注意，以下三行要改为你HBase服务器所在的地址哦。别外，网站都说端口是<code>60000</code>,我下载的版本端口是<code>16000</code>，不要问我为什么，我也不知道</strong></p>
<pre><code>configuration.set(&quot;hbase.zookeeper.property.clientPort&quot;, &quot;2181&quot;); 
configuration.set(&quot;hbase.zookeeper.quorum&quot;, &quot;192.168.90.161&quot;); 
configuration.set(&quot;hbase.master&quot;, &quot;192.168.90.161:16000&quot;); 
</code></pre></li>
<li><p>好了，现在可以运行了，运行一下吧，如果，悲剧的报出了以下错误：</p>
<pre><code>start create table ......
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=36, exceptions:
Fri Aug 28 00:19:07 CST 2015, null, java.net.SocketTimeoutException: callTimeout=60000, callDuration=80060: row &apos;okuc,,&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=MiWiFi-R1CM,52877,1440689832421, seqNum=0

    at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.throwEnrichedException(RpcRetryingCallerWithReadReplicas.java:271)
    at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:223)
    at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:61)
    at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
    at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:320)
    at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:295)
    at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:160)
    at org.apache.hadoop.hbase.client.ClientScanner.&lt;init&gt;(ClientScanner.java:155)
    at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:811)
    at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
    at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
    at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:303)
    at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:313)
    at xyz.okuc.HBaseHello.HbaseTest.createTable(HbaseTest.java:55)
    at xyz.okuc.HBaseHello.HbaseTest.main(HbaseTest.java:40)
Caused by: java.net.SocketTimeoutException: callTimeout=60000, callDuration=80060: row &apos;okuc,,&apos; on table &apos;hbase:meta&apos; at region=hbase:meta,,1.1588230740, hostname=MiWiFi-R1CM,52877,1440689832421, seqNum=0
    at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:159)
    at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:64)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
    at java.lang.Thread.run(Thread.java:722)
Caused by: java.net.UnknownHostException: unknown host: MiWiFi-R1CM
    at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.&lt;init&gt;(RpcClientImpl.java:300)
    at org.apache.hadoop.hbase.ipc.RpcClientImpl.createConnection(RpcClientImpl.java:130)
    at org.apache.hadoop.hbase.ipc.RpcClientImpl.getConnection(RpcClientImpl.java:1284)
    at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1162)
    at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:213)
    at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:287)
    at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$BlockingStub.scan(ClientProtos.java:32651)
    at org.apache.hadoop.hbase.client.ScannerCallable.openScanner(ScannerCallable.java:372)
    at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:199)
    at org.apache.hadoop.hbase.client.ScannerCallable.call(ScannerCallable.java:62)
    at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
    at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:369)
    at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:343)
    at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithRetries(RpcRetryingCaller.java:126)
    ... 4 more
end create table ......
</code></pre></li>
<li><p>怎么办？怎么办？哈哈，一看错误，茅塞顿开，我的HBase服务器的机器名为<code>MiWiFi-R1CM</code>,<code>unknown host: MiWiFi-R1CM</code>不就是在说我的这台服务器找不到么。<br>   解决方案如下，打开win10的<code>c:\Windows\System32\drivers\etc\hosts</code>,添加如下一行记录：</p>
<pre><code>192.168.90.161     MiWiFi-R1CM
</code></pre></li>
<li><p>再次运行程序，顺序结束（你就当没看见log4j的错误吧，配置文件懒得配了）：</p>
<pre><code>start create table ......
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
end create table ......
</code></pre></li>
<li><p>回到HBase服务器下，在<code>bin</code>目录下，我们看看名为<code>okuc</code>的表创建了没，执行命令如下：</p>
<pre><code>[root@MiWiFi-R1CM bin]# ./hbase shell
2015-08-28 00:56:33,956 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
HBase Shell; enter &apos;help&lt;RETURN&gt;&apos; for list of supported commands.
Type &quot;exit&lt;RETURN&gt;&quot; to leave the HBase Shell
Version 1.1.1, rd0a115a7267f54e01c72c603ec53e91ec418292f, Tue Jun 23 14:44:07 PDT 2015

hbase(main):001:0&gt; list
TABLE                                                                                                 
okuc                                                                                                  
1 row(s) in 1.9350 seconds

=&gt; [&quot;okuc&quot;]
hbase(main):002:0&gt; 
</code></pre><p> 可以看到，我们已经成功创建了表<code>okuc</code>。</p>
</li>
<li>####<a href="http://www.52brt.com/source/HBaseHello.7z">猛击这儿，下载源代码吧</a></li>
</ol>

      
    </div>
    <footer>
      
        
        
  
  <div class="tags">
    <a href="/tags/HBase/">HBase</a>
  </div>

        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




<nav id="pagination" >
    
    <a href="/2015/08/30/centos7常用命令/" class="alignleft prev" >Prev</a>
    
    
    <a href="/2015/08/22/《Elasticsearch服务器开发》学习笔记（三）/" class="alignright next" >Next</a>
    
    <div class="clearfix"></div>
</nav>

<!-- ��˵���ۿ� start -->
 <div class="ds-thread" data-thread-key="/2015/08/28/java连接远程HBase/" data-title="java连接远程HBase 1.1.1" data-url="http://www.52brt.com/2015/08/28/java连接远程HBase/"></div>
<!-- ��˵���ۿ� end -->
<!-- ��˵����JS���� start (һ����ҳֻ������һ��) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"okuc"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
<!-- ��˵����JS���� end -->
<section id="comment">
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:www.52brt.com">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/Angularjs/">Angularjs</a><small>6</small></li>
  
    <li><a href="/tags/Bootstrap/">Bootstrap</a><small>5</small></li>
  
    <li><a href="/tags/DateTime/">DateTime</a><small>1</small></li>
  
    <li><a href="/tags/HBase/">HBase</a><small>1</small></li>
  
    <li><a href="/tags/JavaFX/">JavaFX</a><small>1</small></li>
  
    <li><a href="/tags/Nashorn/">Nashorn</a><small>1</small></li>
  
    <li><a href="/tags/Nodejs/">Nodejs</a><small>7</small></li>
  
    <li><a href="/tags/Scala/">Scala</a><small>3</small></li>
  
    <li><a href="/tags/TinkerPop3/">TinkerPop3</a><small>1</small></li>
  
    <li><a href="/tags/ambari/">ambari</a><small>1</small></li>
  
    <li><a href="/tags/centos/">centos</a><small>7</small></li>
  
    <li><a href="/tags/centos6/">centos6</a><small>1</small></li>
  
    <li><a href="/tags/docker/">docker</a><small>3</small></li>
  
    <li><a href="/tags/eclipse/">eclipse</a><small>1</small></li>
  
    <li><a href="/tags/eclipse插件开发/">eclipse插件开发</a><small>1</small></li>
  
    <li><a href="/tags/elasticsearch/">elasticsearch</a><small>6</small></li>
  
    <li><a href="/tags/express/">express</a><small>4</small></li>
  
    <li><a href="/tags/hadoop/">hadoop</a><small>1</small></li>
  
    <li><a href="/tags/hexo/">hexo</a><small>1</small></li>
  
    <li><a href="/tags/java/">java</a><small>15</small></li>
  
    <li><a href="/tags/java8/">java8</a><small>9</small></li>
  
    <li><a href="/tags/kafka/">kafka</a><small>1</small></li>
  
    <li><a href="/tags/lambda/">lambda</a><small>2</small></li>
  
    <li><a href="/tags/linux/">linux</a><small>11</small></li>
  
    <li><a href="/tags/markdown/">markdown</a><small>2</small></li>
  
    <li><a href="/tags/maven/">maven</a><small>1</small></li>
  
    <li><a href="/tags/mongodb/">mongodb</a><small>9</small></li>
  
    <li><a href="/tags/mysql/">mysql</a><small>1</small></li>
  
    <li><a href="/tags/nodejs/">nodejs</a><small>1</small></li>
  
    <li><a href="/tags/scala/">scala</a><small>9</small></li>
  
    <li><a href="/tags/shell/">shell</a><small>5</small></li>
  
    <li><a href="/tags/stream/">stream</a><small>2</small></li>
  
    <li><a href="/tags/svg/">svg</a><small>1</small></li>
  
    <li><a href="/tags/titan/">titan</a><small>1</small></li>
  
    <li><a href="/tags/tomcat/">tomcat</a><small>1</small></li>
  
    <li><a href="/tags/其他/">其他</a><small>1</small></li>
  
    <li><a href="/tags/前端/">前端</a><small>17</small></li>
  
    <li><a href="/tags/可视化/">可视化</a><small>1</small></li>
  
    <li><a href="/tags/图数据库/">图数据库</a><small>1</small></li>
  
    <li><a href="/tags/多线程/">多线程</a><small>1</small></li>
  
    <li><a href="/tags/恢复/">恢复</a><small>1</small></li>
  
    <li><a href="/tags/数据库/">数据库</a><small>9</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2016 okuc
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>